{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_playstore_review_crawler.py",
      "provenance": [],
      "authorship_tag": "ABX9TyNrafUp08SxwbWfxazeq7yn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8eo_5dZR3ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import time, os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "# review link link\n",
        "link = 'https://play.google.com/store/apps/details?id=com.miso&hl=ko&showAllReviews=true'\n",
        "driver = webdriver.Chrome('chromedriver.exe')\n",
        "driver.get(link)\n",
        "\n",
        "# how many scrolls we need\n",
        "scroll_cnt = 10\n",
        "\n",
        "# download chrome driver https://sites.google.com/a/chromium.org/chromedriver/home\n",
        "driver = webdriver.Chrome('chromedriver.exe')\n",
        "driver.get(link)\n",
        "\n",
        "os.makedirs('result', exist_ok=True)\n",
        "\n",
        "for i in range(scroll_cnt):\n",
        "  # scroll to bottom\n",
        "  driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
        "  time.sleep(4)\n",
        "\n",
        "  # click 'Load more' button, if exists\n",
        "\n",
        "\n",
        "# get review containers\n",
        "reviews = driver.find_elements_by_xpath('//*[@jsname=\"fk8dgd\"]//div[@class=\"d15Mdf bAhLNe\"]')\n",
        "\n",
        "print('There are %d reviews avaliable!' % len(reviews))\n",
        "print('Writing the data...')\n",
        "\n",
        "# create empty dataframe to store data\n",
        "df = pd.DataFrame(columns=['name', 'ratings', 'date', 'helpful', 'comment', 'developer_comment'])\n",
        "\n",
        "# get review data\n",
        "for review in reviews:\n",
        "  # parse string to html using bs4\n",
        "  soup = BeautifulSoup(review.get_attribute('innerHTML'), 'html.parser')\n",
        "\n",
        "  # reviewer\n",
        "  name = soup.find(class_='X43Kjb').text\n",
        "\n",
        "  # rating\n",
        "  ratings = int(soup.find('div', role='img').get('aria-label').replace('별표 5개 만점에', '').replace('개를 받았습니다.', '').strip())\n",
        "\n",
        "  # review date\n",
        "  date = soup.find(class_='p2TkOb').text\n",
        "  date = datetime.strptime(date, '%Y년 %m월 %d일') #날짜가 정상적으로 출력되지 않음.*수정필요\n",
        "  date = date.strftime('%Y-%m-%d')\n",
        "\n",
        "  # helpful\n",
        "  helpful = soup.find(class_='jUL89d y92BAb').text\n",
        "  if not helpful:\n",
        "    helpful = 0\n",
        "\n",
        "  # review text\n",
        "  comment = soup.find('span', jsname='fbQN7e').text\n",
        "  if not comment:\n",
        "    comment = soup.find('span', jsname='bN97Pc').text\n",
        "\n",
        "  # developer comment\n",
        "  developer_comment = None\n",
        "  dc_div = soup.find('div', class_='LVQB0b')\n",
        "  if dc_div:\n",
        "    developer_comment = dc_div.text.replace('\\n', ' ')\n",
        "\n",
        "  # append to dataframe\n",
        "  df = df.append({\n",
        "    'name': name,\n",
        "    'ratings': ratings,\n",
        "    'date': date,\n",
        "    'helpful': helpful,\n",
        "    'comment': comment,\n",
        "    'developer_comment': developer_comment\n",
        "  }, ignore_index=True)\n",
        "\n",
        "# finally save the dataframe into csv file\n",
        "filename = datetime.now().strftime('result/%Y-%m-%d_%H-%M-%S.csv')\n",
        "df.to_csv(filename, encoding='utf-8-sig', index=False)\n",
        "driver.stop_client()\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}